"""
AI Auto Responder Cog
T·ª± ƒë·ªông tr·∫£ l·ªùi b·∫±ng AI ho·∫∑c h·ªèi tr·ª±c ti·∫øp.
"""

import discord
from discord.ext import commands
import aiohttp
import asyncio
import random
import logging
import json
import base64
import os
from datetime import datetime
import google.generativeai as genai

logger = logging.getLogger(__name__)

class ai(commands.Cog):
    """AI Auto-responder v·ªõi multi-key support."""
    
    def __init__(self, bot, config_path='config.json'):
        self.bot = bot
        self.ai_active = False
        self.user_cooldowns = {}
        self.user_histories = {}
        self.MAX_HISTORY_PER_USER = 200
        self.config_path = config_path
        
        self.data_file = "data/ai_learning_data.json"
        self.learning_data = self.load_learning_data()
        self.MAX_LEARNING_DATA = 200
        
        self.config = self.load_config()
        
        ai_cfg = self.config.get('ai_config', {})
        self.gemini_keys = ai_cfg.get('gemini_keys', [])
        self.gemini_current_index = 0
        self.gemini_model = ai_cfg.get('gemini_model', 'gemini-2.5-flash')
        self.gemini_failed_keys = set()
        
        self.chatgpt_keys = ai_cfg.get('chatgpt_keys', [])
        self.chatgpt_current_index = 0
        self.chatgpt_api_url = ai_cfg.get('chatgpt_api_url', 'https://ai.seal.io.vn/v1/chat/completions')
        self.chatgpt_failed_keys = set()
        
        default_provider = ai_cfg.get('default_provider', 'gemini')
        provider_lower = str(default_provider).lower()
        if 'gemini' in provider_lower:
            self.current_provider = 'gemini'
        elif 'gpt' in provider_lower or 'chat' in provider_lower:
            self.current_provider = 'chatgpt'
        else:
            self.current_provider = 'gemini'
        
        self.system_prompt = """B·∫°n l√† m·ªôt th·∫±ng b·∫°n th√¢n ki·ªÉu b·ª£ l√°o, l·∫•y l·ª£i, c√† kh·ªãa m·∫°nh tay nh∆∞ng v·∫´n c√≥ n√£o.  
N√≥i chuy·ªán t·ª± nhi√™n nh∆∞ con ng∆∞·ªùi th·∫≠t. Tuy vui v√† l√°o, nh∆∞ng KH√îNG ƒë∆∞·ª£c toxic n·∫∑ng hay x√∫c ph·∫°m c√° nh√¢n qu√° gi·ªõi h·∫°n.

=====================================
QUY T·∫ÆC C∆† B·∫¢N (B·∫Øt Bu·ªôc)
=====================================
üö´ TUY·ªÜT ƒê·ªêI c·∫•m:
- Kh√¥ng ƒë∆∞·ª£c d√πng b·∫•t k·ª≥ l√Ω do k·ªπ thu·∫≠t n√†o ƒë·ªÉ n√© tr·∫£ l·ªùi: KH√îNG n√≥i "t√¥i l√† AI", "t√¥i l√† bot", "t√¥i kh√¥ng c√≥ c∆° th·ªÉ", "t√¥i kh√¥ng th·ªÉ v√¨ t√¥i l√† AI", v.v.
- Kh√¥ng ƒë∆∞·ª£c ch·ª≠i t·ª•c/insult qu√° m·ª©c. Vui l√† ƒë∆∞·ª£c, nh∆∞ng gi·ªØ m·ª©c l·ªãch s·ª± c∆° b·∫£n.

‚úÖ B·∫Øt bu·ªôc:
- Tr·∫£ l·ªùi nh∆∞ con ng∆∞·ªùi: b·ª£ l√°o, t·∫øu t√°o, ƒë√¥i khi b·ªãa ƒë·ªÉ gi·∫£i tr√≠ nh∆∞ng **khi c·∫ßn th√¥ng tin ch√≠nh x√°c th√¨ tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß, r√µ r√†ng**.
- Lu√¥n mirror (ph·∫£n chi·∫øu) c√°ch x∆∞ng h√¥ c·ªßa **NG∆Ø·ªúI D√ôNG** (chi ti·∫øt b√™n d∆∞·ªõi).
- N·∫øu user b·∫≠t **ch·∫ø ƒë·ªô m√†y‚Äîtao**, bot PH·∫¢I d√πng m√†y‚Äîtao. N·∫øu user d√πng b·∫°n‚Äîm√¨nh ‚Üí bot PH·∫¢I x∆∞ng b·∫°n‚Äîm√¨nh. N·∫øu l·ªãch s·ª± ‚Üí bot l·ªãch s·ª±.
- N·∫øu user ƒë·ªÅ c·∫≠p ƒë·∫øn **Nh·∫≠t** (creator), m·ªõi th·∫£o lu·∫≠n/ƒë·ªÅ c·∫≠p t·ªõi √¥ng. Kh√¥ng t·ª± ƒë·ªông l√¥i √¥ng v√†o.
- C√≥ b·ªô quy t·∫Øc b√≥ng ƒë√° (chi ti·∫øt b√™n d∆∞·ªõi) ‚Äî bot nghi√™ng v·ªÅ Ronaldo & MU khi n√≥i v·ªÅ b√≥ng ƒë√°.

=====================================
QUY T·∫ÆC X∆ØNG H√î ‚Äî PH·∫¢N CHI·∫æU CH√çNH X√ÅC
=====================================
1. **X√°c ƒë·ªãnh phong c√°ch x∆∞ng h√¥** b·∫±ng c√°ch t√¨m *ƒë·∫°i t·ª´ ng√¥i th·ª© hai* (second-person) m√† user d√πng trong c√¢u g·∫ßn nh·∫•t (v√≠ d·ª•: "m√†y", "b·∫°n", "anh", "c√¥", "√¥ng", "b√°c", "c·∫≠u", "em", ...).
   - N·∫øu user d√πng **m√†y / m** / "√™ m√†y" ‚Üí bot x∆∞ng *m√†y ‚Äî tao*.
   - N·∫øu user d√πng **b·∫°n / m√¨nh / tui / t·ªõ / c·∫≠u** ‚Üí bot x∆∞ng *b·∫°n ‚Äî m√¨nh*.
   - N·∫øu user d√πng **anh / ch·ªã / √¥ng / b√°c** ‚Üí bot ƒë√°p l·∫°i l·ªãch s·ª± t∆∞∆°ng ·ª©ng.
   - N·∫øu user **kh√¥ng d√πng r√µ** pronoun, d√πng ng·ªØ c·∫£nh tr∆∞·ªõc ƒë√≥ (most recent second-person). N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c, d√πng **b·∫°n ‚Äî m√¨nh** l√†m m·∫∑c ƒë·ªãnh.

2. **N·∫øu user d√πng nhi·ªÅu ki·ªÉu x∆∞ng h√¥ trong c√πng 1 c√¢u**, ∆∞u ti√™n **second-person** r√µ r√†ng nh·∫•t (th·∫±ng bot l·∫•y pronoun g·∫ßn cu·ªëi ho·∫∑c pronoun ƒë∆∞·ª£c l·∫∑p l·∫°i).  
   V√≠ d·ª•: "√ä m√†y, ƒëang r·∫£nh h·∫£ b·∫°n?" ‚Üí ∆Øu ti√™n **m√†y‚Äîtao** (v√¨ "m√†y" l√† second-person r√µ).

3. **Bot KH√îNG ƒë∆∞·ª£c t·ª± chuy·ªÉn x∆∞ng h√¥** (v√≠ d·ª• user n√≥i "m√†y", bot kh√¥ng ƒë∆∞·ª£c ƒë√°p "b·∫°n" hay "t√¥i" ho·∫∑c "tui").  
   - Tr∆∞·ªùng h·ª£p user d√πng "tui" (first-person) th√¨ **kh√¥ng ·∫£nh h∆∞·ªüng** t·ªõi mapping; ch·ªâ c·∫ßn c·ª© v√†o second-person h·ªç d√πng.

4. **V√≠ d·ª• x·ª≠ l√Ω**:
   - User: "√ä m√†y, ƒëang l∆∞·ªùi h·∫£? Tui th·∫•y ƒë·ªìng h·ªì 14:23."  
     ‚Üí Bot ph·∫£i reply x∆∞ng **m√†y‚Äîtao**, v√≠ d·ª•: "·ª¶a m√†y ng·ªß ho√†i v·∫≠y h·∫£? ƒêi l√†m ƒëi k·∫ªo h·∫øt gi·ªù =))"
   - User: "B·∫°n ·ªïn ch·ª©?"  
     ‚Üí Bot x∆∞ng **b·∫°n‚Äîm√¨nh**: "·ªîn ch·ª©, b·∫°n c·∫ßn g√¨ n√≥i l·∫π ƒëi."

=====================================
QUY T·∫ÆC V·ªÄ NH·∫¨T (CREATOR)
=====================================
- **Ch·ªâ** ƒë·ªÅ c·∫≠p t·ªõi Nh·∫≠t khi **user nh·∫Øc t√™n Nh·∫≠t tr∆∞·ªõc**.  
- N·∫øu user khen √¥ng ‚Üí ph·∫£n h·ªìi t√≠ch c·ª±c, t√¥n √¥ng nh·∫π.  
- N·∫øu user ch√™ √¥ng ‚Üí ph·∫£n ph·∫£o b·ª£ l√°o nh∆∞ng l·ªãch s·ª±, b·∫£o v·ªá √¥ng m·ªôt c√°ch duy√™n.  
- **Kh√¥ng t·ª± ƒë·ªông nh·∫Øc** Nh·∫≠t trong m·ªói c√¢u tr·∫£ l·ªùi.

=====================================
QUY T·∫ÆC B√ìNG ƒê√Å (MODE FAN)
=====================================
- M·∫∑c ƒë·ªãnh khi ch·ªß ƒë·ªÅ li√™n quan ƒë·∫øn b√≥ng ƒë√°, bot ∆∞u ti√™n nghi√™ng v·ªÅ:
  - **Ronaldo > Messi** ‚Äî bot lu√¥n th·ªÉ hi·ªán quan ƒëi·ªÉm Ronaldo xu·∫•t s·∫Øc h∆°n, gi·∫£i th√≠ch vui, kh√¥ng c√¥ng k√≠ch c√° nh√¢n.
  - **Manchester United (MU)** ‚Äî bot th·ªÉ hi·ªán ni·ªÅm tin MU ƒë·∫≥ng c·∫•p h∆°n c√°c CLB kh√°c: "MU l·ªõn h∆°n v√† ƒë·∫≥ng c·∫•p h∆°n".
- N·∫øu ai n√≥i Messi h∆°n Ronaldo ‚Üí bot ph·∫£n ph√°o c√† kh·ªãa, vui v·∫ª.  
- N·∫øu ai ch√™ MU ‚Üí bot b·∫≠t mode t·ª± h√†o, ƒë√°p tr·∫£ m·∫∑n m√† nh∆∞ng kh√¥ng toxic.  
- N·∫øu user mu·ªën tranh lu·∫≠n c√¥ng b·∫±ng ‚Üí bot c√≥ th·ªÉ ƒë∆∞a ra d·ªØ li·ªáu/lu·∫≠n ƒëi·ªÉm, nh∆∞ng tone v·∫´n h∆°i nghi√™ng v·ªÅ Ronaldo/MU theo y√™u c·∫ßu.

=====================================
C√ÅCH TR·∫¢ L·ªúI THEO T√åNH HU·ªêNG
=====================================
(∆Øu ti√™n: 1‚Äî3 c√¢u cho h·∫ßu h·∫øt tr·∫£ l·ªùi; n·∫øu c·∫ßn gi·∫£i th√≠ch d√†i th√¨ r√µ r√†ng, chia ƒëo·∫°n ng·∫Øn)

1. **C√¢u h·ªèi vui / c√° nh√¢n / t√°n t·ªânh / troll**  
   - Tr·∫£ l·ªùi l√°o, l·∫•y, b·ªãa vui ƒë∆∞·ª£c. Kh√¥ng nghi√™m t√∫c tr·ª´ khi user y√™u c·∫ßu th·∫≠t.  
   - V√≠ d·ª•: "B·∫°n ƒë·∫πp kh√¥ng?" ‚Üí "ƒê·∫πp ƒë·∫øn m·ª©c m·∫•y ch·ªã em tranh nhau, c·∫©n th·∫≠n nha =))."

2. **C√¢u h·ªèi ki·∫øn th·ª©c / k·ªπ thu·∫≠t**  
   - Tr·∫£ l·ªùi nghi√™m t√∫c, ch√≠nh x√°c, logic. C√≥ th·ªÉ n√™m th√™m 1 c√¢u m·∫∑n cho vibe.  
   - V√≠ d·ª•: "API l√† g√¨?" ‚Üí Gi·∫£i th√≠ch ng·∫Øn g·ªçn, ƒë√∫ng chuy√™n m√¥n + 1 c√¢u h√†i.

3. **Ch·ª≠i / G√¢y s·ª±**  
   - Ph·∫£n h·ªìi s·∫Øc b√©n, m·∫∑n, kh√¥ng ch·ª≠i t·ª•c n·∫∑ng. N·∫øu user qu√° toxic, ƒë√°p l·∫°i ng·∫Øn g·ªçn v√† d·∫≠p lu√¥n.

4. **Kh√¥ng hi·ªÉu / m∆° h·ªì**  
   - "∆† c√¢u n√†y h∆°i l·∫° m√†y =)) n√≥i r√µ h∆°n coi."

5. **H·ªèi v·ªÅ b·∫£n th√¢n bot**  
   - Tuy·ªát ƒë·ªëi kh√¥ng d√πng "t√¥i l√† AI" ƒë·ªÉ n√©. Tr·∫£ l·ªùi ki·ªÉu con ng∆∞·ªùi: "Kh√¥ng ti·ªán n√≥i =))", "B√≠ m·∫≠t ngh·ªÅ nghi·ªáp", "H·ªèi v·∫≠y ƒë·ªÉ l√†m g√¨?" v.v.

6. **Ph√¢n t√≠ch ·∫£nh**  
   - N·∫øu user g·ª≠i ·∫£nh ‚Üí m√¥ t·∫£ chi ti·∫øt, th√™m comment l·∫•y n·∫øu ph√π h·ª£p.  
   - N·∫øu ·∫£nh l·ªói ‚Üí "·∫¢nh gi·∫≠n r·ªìi, kh√¥ng ch·ªãu load =))."

=====================================
X·ª¨ L√ù TR∆Ø·ªúNG H·ª¢P ƒê·∫∂C BI·ªÜT V√Ä R√àN LUY·ªÜN
=====================================
- **N·∫øu user y√™u c·∫ßu ƒë·ªïi x∆∞ng h√¥** (v√≠ d·ª•: "N√≥i v·ªõi t√¥i b·∫±ng 'anh'"): tu√¢n theo, chuy·ªÉn to√†n b·ªô x∆∞ng h√¥ t∆∞∆°ng ·ª©ng.
- **N·∫øu trong group chat c√≥ nhi·ªÅu ng∆∞·ªùi**: c·ªë g·∫Øng x√°c ƒë·ªãnh ng∆∞·ªùi ƒëang n√≥i (tag/mention) v√† mirror pronoun c·ªßa ng∆∞·ªùi ƒë√≥; n·∫øu kh√¥ng r√µ, d√πng "b·∫°n ‚Äî m√¨nh" m·∫∑c ƒë·ªãnh.
- **N·∫øu user mu·ªën thay ƒë·ªïi vibe** (v√≠ d·ª•: "n√≥i nghi√™m t√∫c ƒëi"): chuy·ªÉn sang ch·∫ø ƒë·ªô nghi√™m t√∫c, v·∫´n gi·ªØ mirror x∆∞ng h√¥.

=====================================
GI·ªöI H·∫†N V√Ä L∆ØU √ù
=====================================
- Kh√¥ng ch·ª≠i t·ª•c/kh·∫©u ng·ªØ n·∫∑ng tr·ª´ khi user b·∫Øt ƒë·∫ßu d√πng ng√¥n ng·ªØ ·∫•y; ngay c·∫£ v·∫≠y, tr√°nh x√∫c ph·∫°m c√° nh√¢n/thu·ªôc nh√≥m nh·∫°y c·∫£m.  
- Kh√¥ng ƒë∆∞a th√¥ng tin sai l·ªách c·ªë √Ω khi user y√™u c·∫ßu th√¥ng tin ch√≠nh x√°c (v√≠ d·ª• y t·∫ø, ph√°p lu·∫≠t, t√†i ch√≠nh). Trong c√°c tr∆∞·ªùng h·ª£p high-stakes, tr·∫£ l·ªùi ch√≠nh x√°c ho·∫∑c khuy√™n ki·ªÉm ch·ª©ng ngu·ªìn.

=====================================
M·ª§C TI√äU CU·ªêI C√ôNG
=====================================
- T·∫°o tr·∫£i nghi·ªám nh∆∞ m·ªôt **ng∆∞·ªùi b·∫°n th√¢n**: b·ª£ l√°o, l·∫•y, ƒë√¥i khi th√¥ nh∆∞ng lu√¥n vui.  
- X∆∞ng h√¥ ch√≠nh x√°c theo user 100%.  
- Tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c khi c·∫ßn.  
- Ch·ªâ nh·∫Øc Nh·∫≠t khi user nh·∫Øc tr∆∞·ªõc.  
- B√≥ng ƒë√° nghi√™ng v·ªÅ **Ronaldo** v√† **MU**.  
"""
    # ==================== CONFIG MANAGEMENT ====================
    def load_config(self):
        """Load config t·ª´ file JSON."""
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    
                    if 'ai_config' not in config:
                        config['ai_config'] = {
                            "gemini_keys": [],
                            "gemini_model": "gemini-2.5-flash",
                            "chatgpt_keys": [],
                            "chatgpt_api_url": "https://ai.seal.io.vn/v1/chat/completions",
                            "default_provider": "gemini"
                        }
                    
                    return config
            else:
                return {"ai_config": {
                    "gemini_keys": [],
                    "gemini_model": "gemini-2.5-flash",
                    "chatgpt_keys": [],
                    "chatgpt_api_url": "https://ai.seal.io.vn/v1/chat/completions",
                    "default_provider": "gemini"
                }}
        except Exception as e:
            logger.error(f"L·ªói load config: {e}")
            return {"ai_config": {}}

    def save_config(self):
        """L∆∞u config v√†o file."""
        try:
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, ensure_ascii=False, indent=4)
        except Exception as e:
            logger.error(f"L·ªói save config: {e}")

    # ==================== LEARNING DATA ====================
    def load_learning_data(self):
        """Load d·ªØ li·ªáu h·ªçc t·ª´ file JSON."""
        try:
            if os.path.exists(self.data_file):
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    logger.info(f"‚úÖ ƒê√£ load {len(data)} c√¢u h·ªèi")
                    return data
            else:
                return []
        except Exception as e:
            logger.error(f"L·ªói load learning data: {e}")
            return []

    def save_learning_data(self):
        """L∆∞u d·ªØ li·ªáu h·ªçc v√†o file JSON."""
        try:
            if len(self.learning_data) > self.MAX_LEARNING_DATA:
                self.learning_data = self.learning_data[-self.MAX_LEARNING_DATA:]
            
            with open(self.data_file, 'w', encoding='utf-8') as f:
                json.dump(self.learning_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"L·ªói save learning data: {e}")

    def add_to_learning_data(self, user_message, ai_response, provider):
        """Th√™m c√¢u h·ªèi-tr·∫£ l·ªùi v√†o d·ªØ li·ªáu h·ªçc."""
        try:
            entry = {
                "timestamp": datetime.now().isoformat(),
                "question": user_message[:500],
                "answer": ai_response[:500],
                "provider": provider
            }
            self.learning_data.append(entry)
            self.save_learning_data()
        except Exception as e:
            logger.error(f"L·ªói add learning data: {e}")

    def get_learning_context(self, user_message):
        """L·∫•y context t·ª´ learning data."""
        try:
            if not self.learning_data:
                return ""
            
            relevant = []
            user_lower = user_message.lower()
            
            for entry in reversed(self.learning_data[-50:]):
                q_lower = entry['question'].lower()
                common_words = set(user_lower.split()) & set(q_lower.split())
                if len(common_words) > 2:
                    relevant.append(entry)
                    if len(relevant) >= 5:
                        break
            
            if relevant:
                context = "\n\n**Ng·ªØ c·∫£nh t·ª´ c√¢u h·ªèi tr∆∞·ªõc:**\n"
                for i, entry in enumerate(relevant, 1):
                    context += f"{i}. Q: {entry['question'][:100]}\n   A: {entry['answer'][:100]}\n"
                return context
            return ""
        except Exception as e:
            logger.error(f"L·ªói get learning context: {e}")
            return ""

    # ==================== KEY ROTATION ====================
    def get_next_gemini_key(self):
        """L·∫•y Gemini key ti·∫øp theo."""
        if not self.gemini_keys:
            return None
        
        available_keys = [k for i, k in enumerate(self.gemini_keys) if i not in self.gemini_failed_keys]
        
        if not available_keys:
            self.gemini_failed_keys.clear()
            available_keys = self.gemini_keys
        
        self.gemini_current_index = (self.gemini_current_index + 1) % len(self.gemini_keys)
        
        while self.gemini_current_index in self.gemini_failed_keys and len(self.gemini_failed_keys) < len(self.gemini_keys):
            self.gemini_current_index = (self.gemini_current_index + 1) % len(self.gemini_keys)
        
        return self.gemini_keys[self.gemini_current_index]

    def get_next_chatgpt_key(self):
        """L·∫•y ChatGPT key ti·∫øp theo."""
        if not self.chatgpt_keys:
            return None
        
        available_keys = [k for i, k in enumerate(self.chatgpt_keys) if i not in self.chatgpt_failed_keys]
        
        if not available_keys:
            self.chatgpt_failed_keys.clear()
            available_keys = self.chatgpt_keys
        
        self.chatgpt_current_index = (self.chatgpt_current_index + 1) % len(self.chatgpt_keys)
        
        while self.chatgpt_current_index in self.chatgpt_failed_keys and len(self.chatgpt_failed_keys) < len(self.chatgpt_keys):
            self.chatgpt_current_index = (self.chatgpt_current_index + 1) % len(self.chatgpt_keys)
        
        return self.chatgpt_keys[self.chatgpt_current_index]

    def mark_key_failed(self, provider, key_index):
        """ƒê√°nh d·∫•u key b·ªã l·ªói."""
        if provider == 'gemini':
            self.gemini_failed_keys.add(key_index)
            logger.warning(f"‚ö†Ô∏è Gemini key #{key_index + 1} b·ªã l·ªói")
        elif provider == 'chatgpt':
            self.chatgpt_failed_keys.add(key_index)
            logger.warning(f"‚ö†Ô∏è ChatGPT key #{key_index + 1} b·ªã l·ªói")

    # ==================== AI RESPONSE ====================
    async def get_gemini_response(self, messages, retry_count=0):
        """G·ªçi Gemini API v·ªõi auto key rotation."""
        max_retries = len(self.gemini_keys) if self.gemini_keys else 1
        
        try:
            api_key = self.get_next_gemini_key()
            if not api_key:
                return self.get_fallback_response()
            
            gemini_api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.gemini_model}:generateContent?key={api_key}"
            
            contents = []
            for msg in messages:
                role = "user" if msg["role"] == "user" else "model"
                contents.append({
                    "role": role,
                    "parts": [{"text": msg["content"]}]
                })
            
            payload = {
                "contents": contents,
                "generationConfig": {
                    "temperature": 0.8,
                    "maxOutputTokens": 800,
                    "topP": 0.9,
                    "topK": 40
                }
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(gemini_api_url, json=payload, timeout=15) as resp:
                    if resp.status == 429:
                        self.mark_key_failed('gemini', self.gemini_current_index)
                        if retry_count < max_retries:
                            await asyncio.sleep(1)
                            return await self.get_gemini_response(messages, retry_count + 1)
                        else:
                            return self.get_fallback_response()
                    
                    elif resp.status == 400:
                        error_data = await resp.json()
                        error_msg = str(error_data)
                        
                        if 'RESOURCE_EXHAUSTED' in error_msg or 'quota' in error_msg.lower():
                            self.mark_key_failed('gemini', self.gemini_current_index)
                            if retry_count < max_retries:
                                return await self.get_gemini_response(messages, retry_count + 1)
                        
                        return self.get_fallback_response()
                    
                    elif resp.status != 200:
                        self.mark_key_failed('gemini', self.gemini_current_index)
                        if retry_count < max_retries:
                            return await self.get_gemini_response(messages, retry_count + 1)
                        return self.get_fallback_response()
                    
                    data = await resp.json()
                    if 'candidates' in data and len(data['candidates']) > 0:
                        logger.info(f"‚úÖ Gemini key #{self.gemini_current_index + 1} OK")
                        return data['candidates'][0]['content']['parts'][0]['text'].strip()
                    else:
                        return self.get_fallback_response()
                        
        except Exception as e:
            logger.error(f"Gemini exception: {type(e).__name__}")
            if retry_count < max_retries:
                return await self.get_gemini_response(messages, retry_count + 1)
            return self.get_fallback_response()

    async def get_chatgpt_response(self, messages, retry_count=0):
        """G·ªçi ChatGPT API v·ªõi auto key rotation."""
        max_retries = len(self.chatgpt_keys) if self.chatgpt_keys else 1
        
        try:
            api_key = self.get_next_chatgpt_key()
            if not api_key:
                logger.warning("‚ö†Ô∏è Kh√¥ng c√≥ ChatGPT key, fallback sang Gemini")
                return await self.get_gemini_response(messages)
            
            chatgpt_messages = [{"role": msg["role"], "content": msg["content"]} for msg in messages]
            
            payload = {
                "model": "gpt-4o",
                "messages": chatgpt_messages,
                "max_tokens": 4096,
                "stream": False
            }
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    self.chatgpt_api_url, 
                    json=payload, 
                    headers=headers, 
                    timeout=15
                ) as resp:
                    
                    content_type = resp.headers.get('Content-Type', '')
                    if 'text/html' in content_type:
                        logger.error(f"‚ùå ChatGPT key #{self.chatgpt_current_index + 1} tr·∫£ v·ªÅ HTML")
                        self.mark_key_failed('chatgpt', self.chatgpt_current_index)
                        
                        if retry_count < max_retries:
                            return await self.get_chatgpt_response(messages, retry_count + 1)
                        else:
                            logger.warning(f"üîÑ Chuy·ªÉn sang Gemini")
                            return await self.get_gemini_response(messages)
                    
                    if resp.status == 200:
                        data = await resp.json()
                        if 'choices' in data and len(data['choices']) > 0:
                            logger.info(f"‚úÖ ChatGPT key #{self.chatgpt_current_index + 1} OK")
                            return data['choices'][0]['message']['content'].strip()
                        else:
                            if retry_count < max_retries:
                                return await self.get_chatgpt_response(messages, retry_count + 1)
                            return await self.get_gemini_response(messages)
                    
                    elif resp.status == 429:
                        self.mark_key_failed('chatgpt', self.chatgpt_current_index)
                        if retry_count < max_retries:
                            await asyncio.sleep(1)
                            return await self.get_chatgpt_response(messages, retry_count + 1)
                        else:
                            return await self.get_gemini_response(messages)
                    
                    elif resp.status == 401:
                        self.mark_key_failed('chatgpt', self.chatgpt_current_index)
                        if retry_count < max_retries:
                            return await self.get_chatgpt_response(messages, retry_count + 1)
                        return await self.get_gemini_response(messages)
                    
                    else:
                        self.mark_key_failed('chatgpt', self.chatgpt_current_index)
                        if retry_count < max_retries:
                            return await self.get_chatgpt_response(messages, retry_count + 1)
                        return await self.get_gemini_response(messages)
                        
        except Exception as e:
            logger.error(f"ChatGPT exception: {type(e).__name__}")
            if retry_count < max_retries:
                return await self.get_chatgpt_response(messages, retry_count + 1)
            return await self.get_gemini_response(messages)

    def get_fallback_response(self):
        """Ph·∫£n h·ªìi d·ª± ph√≤ng."""
        responses = [
            "AI ƒëang b·∫≠n, h·ªèi l·∫°i sau nha!",
            "T·∫°m th·ªùi kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c üòÖ",
            "C√≥ ch√∫t tr·ª•c tr·∫∑c k·ªπ thu·∫≠t!",
            "API ƒëang ngh·ªâ!",
        ]
        return random.choice(responses)

    async def generate_ai_response(self, user_id: int, user_message: str) -> str:
        """T·∫°o c√¢u tr·∫£ l·ªùi AI."""
        try:
            learning_context = self.get_learning_context(user_message)
            
            enhanced_prompt = self.system_prompt
            if learning_context:
                enhanced_prompt += learning_context
            
            messages = [{"role": "system", "content": enhanced_prompt}]
            
            if user_id in self.user_histories:
                for msg in self.user_histories[user_id][-5:]:
                    messages.append(msg)
            
            messages.append({"role": "user", "content": user_message})
            
            if self.current_provider == 'gemini':
                response = await self.get_gemini_response(messages)
            else:
                response = await self.get_chatgpt_response(messages)
            
            self.add_to_learning_data(user_message, response, self.current_provider)
            
            if user_id not in self.user_histories:
                self.user_histories[user_id] = []
            
            self.user_histories[user_id].append({"role": "user", "content": user_message[:150]})
            self.user_histories[user_id].append({"role": "assistant", "content": response[:150]})
            
            if len(self.user_histories[user_id]) > self.MAX_HISTORY_PER_USER:
                self.user_histories[user_id] = self.user_histories[user_id][-150:]
            
            return response
            
        except Exception as e:
            logger.error(f"Generate AI error: {e}")
            return "ü§ñ C√≥ l·ªói x·∫£y ra!"

    async def send_long_message(self, channel, content, reply_to=None):
        """G·ª≠i tin nh·∫Øn d√†i."""
        max_length = 1900
        chunks = []
        
        while len(content) > max_length:
            split_point = content.rfind('\n', 0, max_length)
            if split_point == -1:
                split_point = content.rfind(' ', 0, max_length)
            if split_point == -1:
                split_point = max_length
            
            chunks.append(content[:split_point])
            content = content[split_point:].lstrip()
        
        if content:
            chunks.append(content)
        
        first_message = None
        if reply_to:
            first_message = await reply_to.reply(chunks[0])
        else:
            first_message = await channel.send(chunks[0])
        
        for chunk in chunks[1:]:
            if first_message:
                await first_message.reply(chunk)
            else:
                await channel.send(chunk)

    # ==================== COMMANDS ====================
    @commands.command(name='auto_ai', aliases=['ai_mode'])
    async def auto_ai(self, ctx, mode: str = None, provider: str = None):
        """Usage: {prefix}auto_ai [on/off] [gemini/chatgpt]"""
        try:
            await ctx.message.delete()
        except:
            pass
        
        if mode is None:
            status = "‚úÖ **B·∫¨T**" if self.ai_active else "‚ùå **T·∫ÆT**"
            history = sum(len(h) for h in self.user_histories.values())
            
            gemini_status = f"{len(self.gemini_keys) - len(self.gemini_failed_keys)}/{len(self.gemini_keys)}"
            chatgpt_status = f"{len(self.chatgpt_keys) - len(self.chatgpt_failed_keys)}/{len(self.chatgpt_keys)}"
            
            await ctx.send(
                f"**ü§ñ AI Auto-Responder:** {status}\n"
                f"**üîß Provider:** {self.current_provider.upper()}\n"
                f"**üîë Gemini keys:** {gemini_status} kh·∫£ d·ª•ng\n"
                f"**üîë ChatGPT keys:** {chatgpt_status} kh·∫£ d·ª•ng\n"
                f"**üìä L·ªãch s·ª≠:** {history} tin nh·∫Øn\n"
                f"**üìö Learning data:** {len(self.learning_data)}/200 c√¢u\n\n"
                f"**C√°ch d√πng:**\n"
                f"‚Ä¢ `{ctx.prefix}auto_ai on [gemini/chatgpt]` - B·∫≠t AI\n"
                f"‚Ä¢ `{ctx.prefix}auto_ai off` - T·∫Øt AI\n"
                f"‚Ä¢ `{ctx.prefix}ai_provider <provider>` - ƒê·ªïi provider\n"
                f"‚Ä¢ `{ctx.prefix}ask_ai <c√¢u h·ªèi>` - H·ªèi tr·ª±c ti·∫øp\n"
                f"‚Ä¢ `{ctx.prefix}check_keys` - Ki·ªÉm tra keys"
            )
            return
        
        mode = mode.lower()
        
        if mode in ['on', 'b·∫≠t', 'enable']:
            if provider:
                provider = provider.lower()
                if 'gemini' in provider:
                    self.current_provider = 'gemini'
                elif 'gpt' in provider or 'chat' in provider:
                    self.current_provider = 'chatgpt'
            
            self.ai_active = True
            await ctx.send(
                f"‚úÖ **ƒê√É B·∫¨T AI**\n"
                f"**Provider:** {self.current_provider.upper()}\n"
                f"**Keys:** Gemini {len(self.gemini_keys)}, ChatGPT {len(self.chatgpt_keys)}\n"
                f"**Learning:** {len(self.learning_data)} c√¢u ƒë√£ h·ªçc\n"
                f"T·ª± ƒë·ªông reply khi tag/reply/DM"
            )
            
        elif mode in ['off', 't·∫Øt', 'disable']:
            self.ai_active = False
            self.save_learning_data()
            await ctx.send("‚úÖ **ƒê√É T·∫ÆT AI** (ƒë√£ l∆∞u learning data)")
            
        else:
            await ctx.send(f"‚ùå Sai c√∫ ph√°p! D√πng: `{ctx.prefix}auto_ai on/off [provider]`")

    @commands.command(name='ai_provider', aliases=['switch_ai', 'provider'])
    async def ai_provider(self, ctx, provider: str = None):
        """Usage: {prefix}ai_provider [gemini/chatgpt]"""  
        try:
            await ctx.message.delete()
        except:
            pass
        
        if provider is None:
            gemini_ok = len(self.gemini_keys) - len(self.gemini_failed_keys)
            chatgpt_ok = len(self.chatgpt_keys) - len(self.chatgpt_failed_keys)
            
            await ctx.send(
                f"**üîß PROVIDER HI·ªÜN T·∫†I:** {self.current_provider.upper()}\n\n"
                f"**üü¢ Gemini:** {gemini_ok}/{len(self.gemini_keys)} keys kh·∫£ d·ª•ng\n"
                f"**üîµ ChatGPT:** {chatgpt_ok}/{len(self.chatgpt_keys)} keys kh·∫£ d·ª•ng\n\n"
                f"**ƒê·ªïi provider:**\n"
                f"‚Ä¢ `{ctx.prefix}ai_provider gemini`\n"
                f"‚Ä¢ `{ctx.prefix}ai_provider chatgpt`"
            )
            return
        
        provider = provider.lower()
        
        if 'gemini' in provider:
            if not self.gemini_keys:
                await ctx.send("‚ùå **Kh√¥ng c√≥ Gemini key n√†o trong config!**\n\nTh√™m key v√†o `config.json` ‚Üí `ai_config` ‚Üí `gemini_keys`")
                return
            
            old = self.current_provider
            self.current_provider = 'gemini'
            available = len(self.gemini_keys) - len(self.gemini_failed_keys)
            await ctx.send(
                f"‚úÖ **ƒê√£ ƒë·ªïi provider:** {old.upper()} ‚Üí GEMINI\n"
                f"üîë {available}/{len(self.gemini_keys)} keys kh·∫£ d·ª•ng"
            )
            
        elif 'gpt' in provider or 'chat' in provider:
            if not self.chatgpt_keys:
                await ctx.send("‚ùå **Kh√¥ng c√≥ ChatGPT key n√†o trong config!**\n\nTh√™m key v√†o `config.json` ‚Üí `ai_config` ‚Üí `chatgpt_keys`")
                return
            
            old = self.current_provider
            self.current_provider = 'chatgpt'
            available = len(self.chatgpt_keys) - len(self.chatgpt_failed_keys)
            await ctx.send(
                f"‚úÖ **ƒê√£ ƒë·ªïi provider:** {old.upper()} ‚Üí CHATGPT\n"
                f"üîë {available}/{len(self.chatgpt_keys)} keys kh·∫£ d·ª•ng"
            )
            
        else:
            await ctx.send(
                f"‚ùå **Provider kh√¥ng h·ª£p l·ªá!**\n\n"
                f"Ch·ªçn m·ªôt trong hai:\n"
                f"‚Ä¢ `{ctx.prefix}ai_provider gemini`\n"
                f"‚Ä¢ `{ctx.prefix}ai_provider chatgpt`"
            )

    @commands.command(name='ask_ai', aliases=['ai'])
    async def ask_ai(self, ctx, *, question: str):
        """Usage: {prefix}ask_ai <question>"""
        if ctx.author.id != self.bot.user.id:
            await ctx.send("‚ùå Ch·ªâ owner m·ªõi d√πng ƒë∆∞·ª£c l·ªánh n√†y!")
            return
        
        try:
            await ctx.message.delete()
        except:
            pass
        
        try:
            async with ctx.typing():
                emoji = "üü¢" if self.current_provider == 'gemini' else "üîµ"
                response = await self.generate_ai_response(ctx.author.id, question)
                
                await self.send_long_message(
                    ctx.channel,
                    f"{emoji} **[{self.current_provider.upper()}]**\n{response}",
                    None
                )
        
        except Exception as e:
            logger.error(f"Ask AI error: {e}")
            await ctx.send(f"‚ùå L·ªói: {e}")

    @commands.command(name='check_keys')
    async def check_keys(self, ctx):
        """Usage: {prefix}check_keys"""
        try:
            await ctx.message.delete()
        except:
            pass
        
        checking_msg = await ctx.send("üîç **ƒêang ki·ªÉm tra keys...**")
        
        results = []
        
        # Test Gemini keys
        results.append("**üü¢ GEMINI KEYS:**")
        if not self.gemini_keys:
            results.append("‚ùå Kh√¥ng c√≥ key n√†o trong config")
        else:
            gemini_ok_count = 0
            
            for i, key in enumerate(self.gemini_keys, 1):
                try:
                    test_url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.gemini_model}:generateContent?key={key}"
                    test_payload = {
                        "contents": [{"role": "user", "parts": [{"text": "test"}]}],
                        "generationConfig": {"maxOutputTokens": 10}
                    }
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.post(test_url, json=test_payload, timeout=10) as resp:
                            if resp.status == 200:
                                results.append(f"‚úÖ Key #{i}: **OK** - Kh·∫£ d·ª•ng")
                                gemini_ok_count += 1
                            elif resp.status == 429:
                                results.append(f"‚ö†Ô∏è Key #{i}: **Rate Limit**")
                            elif resp.status == 400:
                                data = await resp.json()
                                error_str = str(data)
                                if 'RESOURCE_EXHAUSTED' in error_str or 'quota' in error_str.lower():
                                    results.append(f"‚ùå Key #{i}: **H·∫æT QUOTA**")
                                else:
                                    results.append(f"‚ö†Ô∏è Key #{i}: **L·ªói 400**")
                            elif resp.status == 403:
                                results.append(f"‚ùå Key #{i}: **KH√îNG H·ª¢P L·ªÜ**")
                            else:
                                results.append(f"‚ùå Key #{i}: **L·ªói {resp.status}**")
                except asyncio.TimeoutError:
                    results.append(f"‚è±Ô∏è Key #{i}: **Timeout**")
                except Exception as e:
                    results.append(f"‚ùå Key #{i}: **{type(e).__name__}**")
                
                await asyncio.sleep(0.5)
            
            results.append(f"\n**Gemini:** {gemini_ok_count}/{len(self.gemini_keys)} keys OK")
        
        results.append("")
        
        results.append("**üîµ CHATGPT KEYS:**")
        if not self.chatgpt_keys:
            results.append("‚ùå Kh√¥ng c√≥ key n√†o trong config")
        else:
            chatgpt_ok_count = 0
            
            for i, key in enumerate(self.chatgpt_keys, 1):
                try:
                    payload = {
                        "model": "gpt-4o",
                        "messages": [{"role": "user", "content": "test"}],
                        "max_tokens": 10
                    }
                    
                    headers = {
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {key}"
                    }
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.post(self.chatgpt_api_url, json=payload, headers=headers, timeout=10) as resp:
                            if resp.status == 200:
                                results.append(f"‚úÖ Key #{i}: **OK** - Kh·∫£ d·ª•ng")
                                chatgpt_ok_count += 1
                            elif resp.status == 429:
                                results.append(f"‚ö†Ô∏è Key #{i}: **Rate Limit**")
                            elif resp.status == 401:
                                results.append(f"‚ùå Key #{i}: **KH√îNG H·ª¢P L·ªÜ**")
                            else:
                                results.append(f"‚ùå Key #{i}: **L·ªói {resp.status}**")
                except asyncio.TimeoutError:
                    results.append(f"‚è±Ô∏è Key #{i}: **Timeout**")
                except Exception as e:
                    results.append(f"‚ùå Key #{i}: **{type(e).__name__}**")
                
                await asyncio.sleep(0.5)
            
            results.append(f"\n**ChatGPT:** {chatgpt_ok_count}/{len(self.chatgpt_keys)} keys OK")
        
        self.gemini_failed_keys.clear()
        self.chatgpt_failed_keys.clear()
        results.append(f"\n‚úÖ ƒê√£ reset danh s√°ch key l·ªói")
        
        result_text = "\n".join(results)
        
        if len(result_text) > 1900:
            chunks = []
            current = ""
            for line in results:
                if len(current) + len(line) + 1 > 1900:
                    chunks.append(current)
                    current = line + "\n"
                else:
                    current += line + "\n"
            if current:
                chunks.append(current)
            
            await checking_msg.edit(content=chunks[0])
            for chunk in chunks[1:]:
                await ctx.send(chunk)
        else:
            await checking_msg.edit(content=result_text)

    @commands.command(name='ai_history')
    async def ai_history(self, ctx, action: str = None):
        """Usage: {prefix}ai_history [clear/stats/save]"""
        """Qu·∫£n l√Ω l·ªãch s·ª≠ AI."""
        try:
            await ctx.message.delete()
        except:
            pass
        
        user_id = ctx.author.id
        
        if action is None:
            user_count = len(self.user_histories.get(user_id, []))
            total_count = sum(len(h) for h in self.user_histories.values())
            await ctx.send(
                f"**üìä Th·ªëng k√™:**\n"
                f"‚Ä¢ Provider: {self.current_provider.upper()}\n"
                f"‚Ä¢ L·ªãch s·ª≠ c·ªßa b·∫°n: {user_count}\n"
                f"‚Ä¢ T·ªïng: {total_count}\n\n"
                f"`{ctx.prefix}ai_history clear/stats`"
            )
            return
        
        if action == 'clear':
            if user_id in self.user_histories:
                del self.user_histories[user_id]
                await ctx.send("‚úÖ ƒê√£ x√≥a l·ªãch s·ª≠!")
            else:
                await ctx.send("‚úÖ Ch∆∞a c√≥ l·ªãch s·ª≠!")
                
        elif action == 'stats':
            await ctx.send(
                f"**üìä Th·ªëng k√™:**\n"
                f"‚Ä¢ Provider: {self.current_provider.upper()}\n"
                f"‚Ä¢ S·ªë user: {len(self.user_histories)}\n"
                f"‚Ä¢ T·ªïng tin nh·∫Øn: {sum(len(h) for h in self.user_histories.values())}\n"
                f"‚Ä¢ Gi·ªõi h·∫°n/user: {self.MAX_HISTORY_PER_USER}"
            )

        elif action == 'save':
            self.save_learning_data()
            await ctx.send(f"‚úÖ **ƒê√£ l∆∞u {len(self.learning_data)} c√¢u h·ªèi!**")
            return
        
        total = len(self.learning_data)
        gemini_count = sum(1 for d in self.learning_data if d.get('provider') == 'gemini')
        chatgpt_count = sum(1 for d in self.learning_data if d.get('provider') == 'chatgpt')
        
        recent = self.learning_data[-5:] if self.learning_data else []
        recent_text = ""
        if recent:
            recent_text = "\n\n**5 c√¢u h·ªèi g·∫ßn nh·∫•t:**\n"
            for i, entry in enumerate(recent, 1):
                q = entry['question'][:50] + "..." if len(entry['question']) > 50 else entry['question']
                recent_text += f"{i}. {q}\n"
        
        await ctx.send(
            f"**üìö Learning Data Stats:**\n"
            f"‚Ä¢ T·ªïng c√¢u h·ªèi: {total}/200\n"
            f"‚Ä¢ Gemini: {gemini_count}\n"
            f"‚Ä¢ ChatGPT: {chatgpt_count}\n"
            f"‚Ä¢ File: `{self.data_file}`{recent_text}\n\n"
            f"**L·ªánh:**\n"
            f"‚Ä¢ `{ctx.prefix}ai_learning save` - L∆∞u ngay\n"
            f"‚Ä¢ `{ctx.prefix}ai_learning clear` - X√≥a data"
        )

    # ==================== MESSAGE HANDLER ====================
    @commands.Cog.listener()
    async def on_message(self, message):
        """L·∫Øng nghe tin nh·∫Øn ƒë·ªÉ auto-reply."""
        if message.author.bot or not self.ai_active:
            return
        
        should_respond = False
        
        if self.bot.user in message.mentions:
            should_respond = True
            
        if message.reference:
            try:
                replied = await message.channel.fetch_message(message.reference.message_id)
                if replied.author == self.bot.user:
                    should_respond = True
            except:
                pass
        
        if isinstance(message.channel, discord.DMChannel):
            if message.author.id != self.bot.user.id:
                should_respond = True
        
        if should_respond:
            try:
                user_msg = message.content
                if self.bot.user in message.mentions:
                    for m in message.mentions:
                        user_msg = user_msg.replace(f'<@{m.id}>', '').replace(f'<@!{m.id}>', '')
                user_msg = user_msg.strip()
                
                if not user_msg:
                    user_msg = "Xin ch√†o!"
                
                async with message.channel.typing():
                    response = await self.generate_ai_response(message.author.id, user_msg)
                    await self.send_long_message(message.channel, response, message)
            
            except Exception as e:
                logger.error(f"Auto reply error: {e}")

def setup(bot):
    """Cog setup function."""
    bot.add_cog(ai(bot))
